{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdddMkL1xuNj",
        "outputId": "27275ce5-7073-44e0-9ee6-749ba972814d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'default-of-credit-card-clients-dataset' dataset.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "path = kagglehub.dataset_download(\"uciml/default-of-credit-card-clients-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUvqmTlcxVXx",
        "outputId": "741910c0-9ae5-4ba8-e6fe-d91c445de50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30000, 24])\n"
          ]
        }
      ],
      "source": [
        "# CSV file in the downloaded directory\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        csv_file = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "feature_vec = df.drop('default.payment.next.month', axis=1)\n",
        "target_vec = df['default.payment.next.month']\n",
        "\n",
        "features = torch.tensor(feature_vec.values,dtype=torch.float32)\n",
        "targets = torch.tensor(target_vec.values,dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(features,targets)\n",
        "\n",
        "print(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UHdCpD8JyJ16"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv4JzgNWyN9s",
        "outputId": "212bab36-a06f-4ae7-8542-5c4b6092245e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU detected\n"
          ]
        }
      ],
      "source": [
        "# TODO set device to cuda\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU detected\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"No GPU detected\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a8bzLkBp15Xs"
      },
      "outputs": [],
      "source": [
        "def get_accuracy_and_loss(model, loader, criterion):\n",
        "  model.eval()\n",
        "  my_loss = 0\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    for data, target in loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      pred = output.argmax(dim=1)\n",
        "      correct += pred.eq(target).sum().item()\n",
        "      my_loss += criterion(output, target).item()\n",
        "  return correct/len(loader.dataset), my_loss/len(loader.dataset)\n",
        "\n",
        "def get_auc(model, loader, device):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            probs = torch.softmax(output, dim=1)[:, 1]\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_targets.append(target.cpu())\n",
        "    all_probs = torch.cat(all_probs).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    return roc_auc_score(all_targets, all_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F1U6oQwY1tDY"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(24, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yd86TvxZ1u--"
      },
      "outputs": [],
      "source": [
        "# TODO create a network and move it to GPU\n",
        "\n",
        "model = NN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5JczvYl2Gmm",
        "outputId": "3b364697-83b1-46a1-d076-74dd4a195536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 done.\n",
            "Train accuracy: 0.7754583333333334\n",
            "Train loss: 0.01637953600163261\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015577536756793658\n",
            "Val AUC: 0.6645\n",
            "Epoch 1 done.\n",
            "Train accuracy: 0.7773333333333333\n",
            "Train loss: 0.0159387499888738\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015523913234472275\n",
            "Val AUC: 0.6599\n",
            "Epoch 2 done.\n",
            "Train accuracy: 0.7773333333333333\n",
            "Train loss: 0.015795223532865443\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015362561563650767\n",
            "Val AUC: 0.6788\n",
            "Epoch 3 done.\n",
            "Train accuracy: 0.7774583333333334\n",
            "Train loss: 0.01570082364976406\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015271286035577456\n",
            "Val AUC: 0.6795\n",
            "Epoch 4 done.\n",
            "Train accuracy: 0.777\n",
            "Train loss: 0.015620595299949249\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015213162461916606\n",
            "Val AUC: 0.6897\n",
            "Epoch 5 done.\n",
            "Train accuracy: 0.7773333333333333\n",
            "Train loss: 0.015566968906670808\n",
            "Val accuracy: 0.7843333333333333\n",
            "Val loss: 0.015509137173493703\n",
            "Val AUC: 0.6631\n",
            "Epoch 6 done.\n",
            "Train accuracy: 0.777125\n",
            "Train loss: 0.015541706966857116\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.01528018781542778\n",
            "Val AUC: 0.6863\n",
            "Epoch 7 done.\n",
            "Train accuracy: 0.7776666666666666\n",
            "Train loss: 0.01550882447262605\n",
            "Val accuracy: 0.7846666666666666\n",
            "Val loss: 0.015142003506422043\n",
            "Val AUC: 0.6934\n",
            "Epoch 8 done.\n",
            "Train accuracy: 0.77725\n",
            "Train loss: 0.015466059647500516\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015196042915185292\n",
            "Val AUC: 0.6848\n",
            "Epoch 9 done.\n",
            "Train accuracy: 0.7777916666666667\n",
            "Train loss: 0.01553306182473898\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015191490103801091\n",
            "Val AUC: 0.6901\n",
            "Epoch 10 done.\n",
            "Train accuracy: 0.7772083333333333\n",
            "Train loss: 0.015488099521646898\n",
            "Val accuracy: 0.7845\n",
            "Val loss: 0.015248678545157116\n",
            "Val AUC: 0.6948\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "patience = 3\n",
        "epochs_without_improve = 0\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total_count = 0\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total_count += data.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch} done.\")\n",
        "    train_accuracy = correct / total_count\n",
        "    train_loss = train_loss / total_count\n",
        "    print(f\"Train accuracy: {train_accuracy}\")\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    print(f\"Train loss: {train_loss}\")\n",
        "    train_losses.append(train_loss)\n",
        "    val_accuracy, val_loss = get_accuracy_and_loss(model, val_loader, criterion)\n",
        "    print(f\"Val accuracy: {val_accuracy}\")\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    print(f\"Val loss: {val_loss}\")\n",
        "    val_losses.append(val_loss)\n",
        "    val_auc = get_auc(model, val_loader, device)\n",
        "    print(f\"Val AUC: {val_auc:.4f}\")\n",
        "    # Check for improvement\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      torch.save(model.state_dict(), 'best_model.pth')\n",
        "      epochs_without_improve = 0\n",
        "    else:\n",
        "      epochs_without_improve += 1\n",
        "      if epochs_without_improve >= patience:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
