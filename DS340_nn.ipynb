{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code ran in Google Colab for training purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdddMkL1xuNj",
        "outputId": "9e944b03-5161-4c8b-c1d0-3da699776c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'default-of-credit-card-clients-dataset' dataset.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "path = kagglehub.dataset_download(\"uciml/default-of-credit-card-clients-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUvqmTlcxVXx",
        "outputId": "2b997719-15f0-4c16-ae9d-4e663e5c7df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30000, 24])\n"
          ]
        }
      ],
      "source": [
        "# CSV file in the downloaded directory\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        csv_file = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "feature_vec = df.drop('default.payment.next.month', axis=1)\n",
        "target_vec = df['default.payment.next.month']\n",
        "\n",
        "features = torch.tensor(feature_vec.values,dtype=torch.float32)\n",
        "targets = torch.tensor(target_vec.values,dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(features,targets)\n",
        "\n",
        "print(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "UHdCpD8JyJ16"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv4JzgNWyN9s",
        "outputId": "e6e4a0aa-33c3-484c-f743-9c934d1eb55f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU detected\n"
          ]
        }
      ],
      "source": [
        "# TODO set device to cuda\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU detected\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"No GPU detected\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "a8bzLkBp15Xs"
      },
      "outputs": [],
      "source": [
        "def get_accuracy_and_loss(model, loader, criterion):\n",
        "  model.eval()\n",
        "  my_loss = 0\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    for data, target in loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      pred = output.argmax(dim=1)\n",
        "      correct += pred.eq(target).sum().item()\n",
        "      my_loss += criterion(output, target).item()\n",
        "  return correct/len(loader.dataset), my_loss/len(loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "F1U6oQwY1tDY"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(24, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "Yd86TvxZ1u--"
      },
      "outputs": [],
      "source": [
        "# TODO create a network and move it to GPU\n",
        "\n",
        "model = NN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5JczvYl2Gmm",
        "outputId": "d96048c6-6dcd-4bf1-eacf-85c081a7fa43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 done.\n",
            "Train accuracy: 0.7787083333333333\n",
            "Train loss: 0.015268189246455828\n",
            "Val accuracy: 0.7806666666666666\n",
            "Val loss: 0.015716490646203358\n",
            "Epoch 1 done.\n",
            "Train accuracy: 0.7778333333333334\n",
            "Train loss: 0.01531418011834224\n",
            "Val accuracy: 0.7803333333333333\n",
            "Val loss: 0.015587726160883903\n",
            "Epoch 2 done.\n",
            "Train accuracy: 0.777625\n",
            "Train loss: 0.015299207189430793\n",
            "Val accuracy: 0.7803333333333333\n",
            "Val loss: 0.01537394835303227\n",
            "Epoch 3 done.\n",
            "Train accuracy: 0.778\n",
            "Train loss: 0.015312454582502445\n",
            "Val accuracy: 0.7803333333333333\n",
            "Val loss: 0.015430979105333488\n",
            "Epoch 4 done.\n",
            "Train accuracy: 0.778375\n",
            "Train loss: 0.015267308649917443\n",
            "Val accuracy: 0.7806666666666666\n",
            "Val loss: 0.015574835518995921\n",
            "Epoch 5 done.\n",
            "Train accuracy: 0.779\n",
            "Train loss: 0.015298629229267438\n",
            "Val accuracy: 0.7806666666666666\n",
            "Val loss: 0.015391796367863813\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "patience = 3\n",
        "epochs_without_improve = 0\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total_count = 0\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total_count += data.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch} done.\")\n",
        "    train_accuracy = correct / total_count\n",
        "    train_loss = train_loss / total_count\n",
        "    print(f\"Train accuracy: {train_accuracy}\")\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    print(f\"Train loss: {train_loss}\")\n",
        "    train_losses.append(train_loss)\n",
        "    val_accuracy, val_loss = get_accuracy_and_loss(model, val_loader, criterion)\n",
        "    print(f\"Val accuracy: {val_accuracy}\")\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    print(f\"Val loss: {val_loss}\")\n",
        "    val_losses.append(val_loss)\n",
        "    # Check for improvement\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      torch.save(model.state_dict(), 'best_model.pth')\n",
        "      epochs_without_improve = 0\n",
        "    else:\n",
        "      epochs_without_improve += 1\n",
        "      if epochs_without_improve >= patience:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
